{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Project -  Dealing with Missing Numerical Values\n",
    "\n",
    "\n",
    "In this project, I discuss various data preprocessing techniques to handle missing numerical values. The contents of this project are categorized into various sections which are listed in table of contents as follows:-\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "1.\tIntroduction\n",
    "\n",
    "2.\tSource dataset\n",
    "\n",
    "3.\tDealing with missing numerical values\n",
    "\n",
    "4.\tDrop missing values with dropna()\n",
    "\n",
    "5.\tFill missing values with a test statistic\n",
    "\n",
    "6.\tFill missing values with Imputer\n",
    "\n",
    "7.\tBuild a prediction model\n",
    "\n",
    "8.\tKNN Imputation\n",
    "\n",
    "9.\tCheck with ASSERT statement\n",
    "\n",
    "10.\tReferences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Negli ultimi decenni, il Machine Learning (ML) ha guadagnato un'immensa popolarità nel risolvere i problemi di business del mondo reale. È emerso come uno strumento tecnologico per le aziende che cercano di aumentare la produttività e il profitto. I praticanti di ML raccolgono dati del mondo reale e scrivono algoritmi per risolvere problemi di business. Il successo degli algoritmi di ML dipende dalla qualità dei dati. I dati devono essere privi di errori e discrepanze. Deve aderire a uno standard specifico in modo che gli algoritmi di ML possano accettarli. Ma questo non accade nella realtà.\n",
    "\n",
    "In realtà, i dati hanno i loro limiti. I dati sono sporchi. È incompleto, rumoroso e incoerente.  I dati incompleti significano che hanno valori mancanti e mancano di alcuni attributi. I dati possono essere rumorosi perché contengono errori e outlier e quindi non producono i risultati desiderati. Infine, i dati possono essere incoerenti perché contengono discrepanze nei dati o dati duplicati.\n",
    "\n",
    "Quindi, i professionisti del ML devono intraprendere azioni per trasformare i dati grezzi in dati standardizzati e adatti agli algoritmi di ML.  Si tratta di pulire, trasformare e standardizzare i dati per rimuovere tutte le inadeguatezze e le irregolarità nei dati. Queste azioni sono note collettivamente come **Preelaborazione dei dati**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Source dataset\n",
    "\n",
    "\n",
    "Ho usato il set di dati wiki4HE.csv per questo progetto. Ho scaricato questo set di dati dall'UCI Machine Learning Repository. Il set di dati descrive i risultati del sondaggio dei membri della facoltà di due università spagnole sull'uso didattico di Wikipedia.\n",
    "\n",
    "\n",
    "Il set di dati contiene 53 attributi e 913 istanze. Dei 53 attributi, 4 sono di tipo numerico e 49 sono di tipo testo o carattere.\n",
    "\n",
    "\n",
    "Il set di dati può essere trovato al seguente url-\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/wiki4HE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dealing with missing numerical values\n",
    "\n",
    "È uno scenario molto comune che quando si guardano i dati del mondo reale, uno scienziato dei dati può imbattersi in valori mancanti. Questi valori mancanti potrebbero essere dovuti a un processo di inserimento dei dati soggetto a errori, a metodi di raccolta dei dati sbagliati, a certi valori non applicabili, a particolari campi lasciati in bianco in un'indagine o al rifiuto di rispondere da parte dell'intervistato. Qualunque sia la ragione del valore mancante, il data scientist deve trovare il modo di gestire questi valori mancanti. Sa che i valori mancanti devono essere gestiti con attenzione, perché danno risultati sbagliati se li ignoriamo semplicemente. Deve rispondere se deve cancellare questi valori mancanti o sostituirli con una statistica adeguata. Il primo passo per trattare correttamente i valori mancanti è identificarli.\n",
    "\n",
    "\n",
    "L'ispezione iniziale dei dati ci aiuta a rilevare se ci sono valori mancanti nel set di dati. Può essere fatto tramite l'analisi esplorativa dei dati. Quindi, è sempre importante che uno scienziato dei dati esegua sempre l'analisi esplorativa dei dati (EDA) per identificare correttamente i valori mancanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "\n",
    "dataset = \"dataset/uci - missing data/wiki4HE/wiki4HE.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "\n",
    "Di seguito è riportato l'elenco dei comandi per identificare i valori mancanti con EDA.\n",
    "\n",
    "\n",
    "1.\t`df.head()`\n",
    "\n",
    "Questo produrrà le prime cinque righe del set di dati. Ci darà una visione rapida sulla presenza di 'NaN' o '?' '-1' o '0' o spazi vuoti \"\" nel set di dati. Se necessario, possiamo visualizzare un numero maggiore di righe specificando il numero di righe all'interno della parentesi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AGE  GENDER DOMAIN  PhD YEARSEXP  UNIVERSITY UOC_POSITION OTHER_POSITION  \\\n",
      "0   40       0      2    1       14           1            2              ?   \n",
      "1   42       0      5    1       18           1            2              ?   \n",
      "2   37       0      4    1       13           1            3              ?   \n",
      "3   40       0      4    0       13           1            3              ?   \n",
      "4   51       0      6    0        8           1            3              ?   \n",
      "\n",
      "  OTHERSTATUS USERWIKI  ... BI2 Inc1 Inc2 Inc3 Inc4 Exp1 Exp2 Exp3 Exp4 Exp5  \n",
      "0           ?        0  ...   3    5    5    5    5    4    4    4    1    2  \n",
      "1           ?        0  ...   2    4    4    3    4    2    2    4    2    4  \n",
      "2           ?        0  ...   1    5    3    5    5    2    2    2    1    3  \n",
      "3           ?        0  ...   3    3    4    4    3    4    4    3    3    4  \n",
      "4           ?        1  ...   5    5    5    4    4    5    5    5    4    4  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# View the first 5 rows of the dataset\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretazione**\n",
    "\n",
    "Possiamo vedere che ci sono molti valori mancanti nel set di dati. Le colonne **OTHER_POSITION** e **OTHERSTATUS** contengono valori mancanti.\n",
    "\n",
    "La colonna **GENDER** contiene degli zeri. Potrebbe essere perché **Male** è codificato come 1 e **Female** è codificato come 0.\n",
    "\n",
    "Dobbiamo esplorare ulteriormente il set di dati per confermare quali colonne contengono i valori mancanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `df.info()`\n",
    "\n",
    "Questo comando è molto utile per rilevare i valori mancanti nel set di dati. Ci dirà il numero totale di osservazioni non nulle presenti, compreso il numero totale di voci. Quando il numero di voci non è uguale al numero di osservazioni non nulle, sappiamo che ci sono valori mancanti nel set di dati.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913 entries, 0 to 912\n",
      "Data columns (total 53 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   AGE             913 non-null    int64 \n",
      " 1   GENDER          913 non-null    int64 \n",
      " 2   DOMAIN          913 non-null    object\n",
      " 3   PhD             913 non-null    int64 \n",
      " 4   YEARSEXP        913 non-null    object\n",
      " 5   UNIVERSITY      913 non-null    int64 \n",
      " 6   UOC_POSITION    913 non-null    object\n",
      " 7   OTHER_POSITION  913 non-null    object\n",
      " 8   OTHERSTATUS     913 non-null    object\n",
      " 9   USERWIKI        913 non-null    object\n",
      " 10  PU1             913 non-null    object\n",
      " 11  PU2             913 non-null    object\n",
      " 12  PU3             913 non-null    object\n",
      " 13  PEU1            913 non-null    object\n",
      " 14  PEU2            913 non-null    object\n",
      " 15  PEU3            913 non-null    object\n",
      " 16  ENJ1            913 non-null    object\n",
      " 17  ENJ2            913 non-null    object\n",
      " 18  Qu1             913 non-null    object\n",
      " 19  Qu2             913 non-null    object\n",
      " 20  Qu3             913 non-null    object\n",
      " 21  Qu4             913 non-null    object\n",
      " 22  Qu5             913 non-null    object\n",
      " 23  Vis1            913 non-null    object\n",
      " 24  Vis2            913 non-null    object\n",
      " 25  Vis3            913 non-null    object\n",
      " 26  Im1             913 non-null    object\n",
      " 27  Im2             913 non-null    object\n",
      " 28  Im3             913 non-null    object\n",
      " 29  SA1             913 non-null    object\n",
      " 30  SA2             913 non-null    object\n",
      " 31  SA3             913 non-null    object\n",
      " 32  Use1            913 non-null    object\n",
      " 33  Use2            913 non-null    object\n",
      " 34  Use3            913 non-null    object\n",
      " 35  Use4            913 non-null    object\n",
      " 36  Use5            913 non-null    object\n",
      " 37  Pf1             913 non-null    object\n",
      " 38  Pf2             913 non-null    object\n",
      " 39  Pf3             913 non-null    object\n",
      " 40  JR1             913 non-null    object\n",
      " 41  JR2             913 non-null    object\n",
      " 42  BI1             913 non-null    object\n",
      " 43  BI2             913 non-null    object\n",
      " 44  Inc1            913 non-null    object\n",
      " 45  Inc2            913 non-null    object\n",
      " 46  Inc3            913 non-null    object\n",
      " 47  Inc4            913 non-null    object\n",
      " 48  Exp1            913 non-null    object\n",
      " 49  Exp2            913 non-null    object\n",
      " 50  Exp3            913 non-null    object\n",
      " 51  Exp4            913 non-null    object\n",
      " 52  Exp5            913 non-null    object\n",
      "dtypes: int64(4), object(49)\n",
      "memory usage: 378.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# View the summary of the dataframe\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Il comando precedente mostra che non ci sono valori mancanti nel set di dati. Ma questo non è vero. Il set di dati contiene valori mancanti. Potrebbe essere perché i valori mancanti sono codificati in modi diversi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode missing numerical values\n",
    "\n",
    "\n",
    "I valori mancanti sono codificati in modi diversi. Possono apparire come \"NaN\", \"NA\", \"?\", Zero \"0\", \"xx\", meno uno \"-1\" o uno spazio vuoto \"\". Dobbiamo utilizzare vari metodi panda per gestire i valori mancanti. Tuttavia, i panda riconoscono sempre i valori mancanti come \"NaN\". Quindi, è essenziale convertire prima tutti i caratteri \"?\", Zeri \"0\", \"xx\", meno \"-1\" o spazi vuoti \"\" in \"NaN\". Se i valori mancanti non sono identificati come \"NaN\", dobbiamo prima convertire o sostituire tale voce non \"NaN\" con un \"NaN\".\n",
    "\n",
    "### Convert '?' to ‘NaN’\n",
    "\n",
    "`df[df == '?'] = np.nan`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert '?' to 'NaN'\n",
    "\n",
    "df[df == '?'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AGE  GENDER DOMAIN  PhD YEARSEXP  UNIVERSITY UOC_POSITION OTHER_POSITION  \\\n",
      "0   40       0      2    1       14           1            2            NaN   \n",
      "1   42       0      5    1       18           1            2            NaN   \n",
      "2   37       0      4    1       13           1            3            NaN   \n",
      "3   40       0      4    0       13           1            3            NaN   \n",
      "4   51       0      6    0        8           1            3            NaN   \n",
      "\n",
      "  OTHERSTATUS USERWIKI  ... BI2 Inc1 Inc2 Inc3 Inc4 Exp1 Exp2 Exp3 Exp4 Exp5  \n",
      "0         NaN        0  ...   3    5    5    5    5    4    4    4    1    2  \n",
      "1         NaN        0  ...   2    4    4    3    4    2    2    4    2    4  \n",
      "2         NaN        0  ...   1    5    3    5    5    2    2    2    1    3  \n",
      "3         NaN        0  ...   3    3    4    4    3    4    4    3    3    4  \n",
      "4         NaN        1  ...   5    5    5    4    4    5    5    5    4    4  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# View the first 5 rows of the dataset again\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913 entries, 0 to 912\n",
      "Data columns (total 53 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   AGE             913 non-null    int64 \n",
      " 1   GENDER          913 non-null    int64 \n",
      " 2   DOMAIN          911 non-null    object\n",
      " 3   PhD             913 non-null    int64 \n",
      " 4   YEARSEXP        890 non-null    object\n",
      " 5   UNIVERSITY      913 non-null    int64 \n",
      " 6   UOC_POSITION    800 non-null    object\n",
      " 7   OTHER_POSITION  652 non-null    object\n",
      " 8   OTHERSTATUS     373 non-null    object\n",
      " 9   USERWIKI        909 non-null    object\n",
      " 10  PU1             906 non-null    object\n",
      " 11  PU2             902 non-null    object\n",
      " 12  PU3             908 non-null    object\n",
      " 13  PEU1            909 non-null    object\n",
      " 14  PEU2            899 non-null    object\n",
      " 15  PEU3            816 non-null    object\n",
      " 16  ENJ1            906 non-null    object\n",
      " 17  ENJ2            896 non-null    object\n",
      " 18  Qu1             906 non-null    object\n",
      " 19  Qu2             903 non-null    object\n",
      " 20  Qu3             898 non-null    object\n",
      " 21  Qu4             891 non-null    object\n",
      " 22  Qu5             884 non-null    object\n",
      " 23  Vis1            841 non-null    object\n",
      " 24  Vis2            796 non-null    object\n",
      " 25  Vis3            905 non-null    object\n",
      " 26  Im1             891 non-null    object\n",
      " 27  Im2             893 non-null    object\n",
      " 28  Im3             856 non-null    object\n",
      " 29  SA1             902 non-null    object\n",
      " 30  SA2             901 non-null    object\n",
      " 31  SA3             902 non-null    object\n",
      " 32  Use1            899 non-null    object\n",
      " 33  Use2            896 non-null    object\n",
      " 34  Use3            904 non-null    object\n",
      " 35  Use4            890 non-null    object\n",
      " 36  Use5            898 non-null    object\n",
      " 37  Pf1             902 non-null    object\n",
      " 38  Pf2             907 non-null    object\n",
      " 39  Pf3             899 non-null    object\n",
      " 40  JR1             886 non-null    object\n",
      " 41  JR2             860 non-null    object\n",
      " 42  BI1             881 non-null    object\n",
      " 43  BI2             870 non-null    object\n",
      " 44  Inc1            878 non-null    object\n",
      " 45  Inc2            878 non-null    object\n",
      " 46  Inc3            876 non-null    object\n",
      " 47  Inc4            871 non-null    object\n",
      " 48  Exp1            900 non-null    object\n",
      " 49  Exp2            902 non-null    object\n",
      " 50  Exp3            900 non-null    object\n",
      " 51  Exp4            899 non-null    object\n",
      " 52  Exp5            900 non-null    object\n",
      "dtypes: int64(4), object(49)\n",
      "memory usage: 378.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# View the summary of the dataframe again\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretazione**\n",
    "\n",
    "Ora possiamo vedere che ci sono molte colonne contenenti valori mancanti. Dovremmo visualizzare i nomi delle colonne del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'GENDER', 'DOMAIN', 'PhD', 'YEARSEXP', 'UNIVERSITY',\n",
      "       'UOC_POSITION', 'OTHER_POSITION', 'OTHERSTATUS', 'USERWIKI', 'PU1',\n",
      "       'PU2', 'PU3', 'PEU1', 'PEU2', 'PEU3', 'ENJ1', 'ENJ2', 'Qu1', 'Qu2',\n",
      "       'Qu3', 'Qu4', 'Qu5', 'Vis1', 'Vis2', 'Vis3', 'Im1', 'Im2', 'Im3', 'SA1',\n",
      "       'SA2', 'SA3', 'Use1', 'Use2', 'Use3', 'Use4', 'Use5', 'Pf1', 'Pf2',\n",
      "       'Pf3', 'JR1', 'JR2', 'BI1', 'BI2', 'Inc1', 'Inc2', 'Inc3', 'Inc4',\n",
      "       'Exp1', 'Exp2', 'Exp3', 'Exp4', 'Exp5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# View the column names of dataframe\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `df.describe()`\n",
    "\n",
    "Questo mostrerà le statistiche di riepilogo di tutte le caratteristiche e le etichette osservate. La statistica più importante è il valore minimo. Se vediamo -1 o 0 nelle nostre osservazioni, possiamo sospettare un valore mancante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AGE      GENDER         PhD  UNIVERSITY\n",
      "count  913.000000  913.000000  913.000000  913.000000\n",
      "mean    42.246440    0.424973    0.464403    1.123768\n",
      "std      8.058418    0.494610    0.499005    0.329497\n",
      "min     23.000000    0.000000    0.000000    1.000000\n",
      "25%     36.000000    0.000000    0.000000    1.000000\n",
      "50%     42.000000    0.000000    0.000000    1.000000\n",
      "75%     47.000000    1.000000    1.000000    1.000000\n",
      "max     69.000000    1.000000    1.000000    2.000000\n"
     ]
    }
   ],
   "source": [
    "# View the descriptive statistics of the dataframe\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Possiamo vedere che ci sono quattro colonne di tipi di dati interi: ** AGE **, ** GENDER **, ** PhD ** e ** UNIVERSITY **.\n",
    "\n",
    "Nella colonna ** ETÀ **, i valori massimo e minimo sono 69 e 23. Il valore mediano è 42 e il conteggio è 913. Non sospettiamo alcun valore mancante in questa colonna.\n",
    "\n",
    "Allo stesso modo, la spiegazione vale per le colonne ** PhD ** e ** UNIVERSITY **.\n",
    "\n",
    "La colonna ** GENDER ** ha solo due possibili valori 0 e 1. Ciò è ragionevole perché 0 è per la femmina e 1 per il maschio.\n",
    "\n",
    "Quindi, non troviamo alcun valore mancante nelle quattro colonne precedenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\t`df.isnull()`\n",
    "\n",
    "Il comando precedente controlla se ogni cella in un dataframe contiene valori mancanti o meno. Se la cella contiene un valore mancante, restituisce True, altrimenti restituisce False.\n",
    "\n",
    "\n",
    "5.\t`df.isnull.sum()`\n",
    "\n",
    "Il comando precedente restituisce il numero totale di valori mancanti in ogni colonna nel set di dati.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE                 0\n",
      "GENDER              0\n",
      "DOMAIN              2\n",
      "PhD                 0\n",
      "YEARSEXP           23\n",
      "UNIVERSITY          0\n",
      "UOC_POSITION      113\n",
      "OTHER_POSITION    261\n",
      "OTHERSTATUS       540\n",
      "USERWIKI            4\n",
      "PU1                 7\n",
      "PU2                11\n",
      "PU3                 5\n",
      "PEU1                4\n",
      "PEU2               14\n",
      "PEU3               97\n",
      "ENJ1                7\n",
      "ENJ2               17\n",
      "Qu1                 7\n",
      "Qu2                10\n",
      "Qu3                15\n",
      "Qu4                22\n",
      "Qu5                29\n",
      "Vis1               72\n",
      "Vis2              117\n",
      "Vis3                8\n",
      "Im1                22\n",
      "Im2                20\n",
      "Im3                57\n",
      "SA1                11\n",
      "SA2                12\n",
      "SA3                11\n",
      "Use1               14\n",
      "Use2               17\n",
      "Use3                9\n",
      "Use4               23\n",
      "Use5               15\n",
      "Pf1                11\n",
      "Pf2                 6\n",
      "Pf3                14\n",
      "JR1                27\n",
      "JR2                53\n",
      "BI1                32\n",
      "BI2                43\n",
      "Inc1               35\n",
      "Inc2               35\n",
      "Inc3               37\n",
      "Inc4               42\n",
      "Exp1               13\n",
      "Exp2               11\n",
      "Exp3               13\n",
      "Exp4               14\n",
      "Exp5               13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View missing values in each column in the dataset\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Possiamo vedere che c'è una colonna ** YEARSEXP ** che contiene 23 valori mancanti. Nella descrizione del set di dati, viene indicato che questa colonna indica il numero di anni di esperienza di insegnamento universitario e il suo tipo di dati è numerico. Ma il comando df.info () mostra che è di tipo di dati oggetto. Quindi, dobbiamo cambiare il suo tipo di dati.\n",
    "\n",
    "Allo stesso modo, le ultime cinque colonne ** Exp1 **, ** Exp2 **, ** Exp3 **, ** Exp4 ** e ** Exp5 ** indicano il numero di anni di esperienza. Contengono rispettivamente 13, 11, 13, 14 e 13 valori mancanti. Hanno tipi di dati numerici. Ma il comando df.info () mostra che sono di tipi di dati oggetto. Quindi, dobbiamo cambiare anche i loro tipi di dati.\n",
    "\n",
    "Tutte le altre colonne sono di tipi di dati di testo.\n",
    "\n",
    "Quindi, dobbiamo creare un sottoinsieme di queste colonne dal set di dati sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataframe df with above columns\n",
    "\n",
    "df_sub = df[['YEARSEXP', 'Exp1', 'Exp2', 'Exp3', 'Exp4', 'Exp5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP    object\n",
      "Exp1        object\n",
      "Exp2        object\n",
      "Exp3        object\n",
      "Exp4        object\n",
      "Exp5        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of columns of df_sub\n",
    "\n",
    "print(df_sub.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Possiamo vedere che il tipo di dati delle colonne del dataframe di df_sub è object. Dovremmo convertirlo in un tipo di dati intero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns of df_sub into integer data types\n",
    "\n",
    "df_sub = df_sub.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP    float64\n",
      "Exp1        float64\n",
      "Exp2        float64\n",
      "Exp3        float64\n",
      "Exp4        float64\n",
      "Exp5        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_sub.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Possiamo vedere che tutte le colonne di df_sub dataframe vengono convertite in tipi di dati numerici float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913 entries, 0 to 912\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   YEARSEXP  890 non-null    float64\n",
      " 1   Exp1      900 non-null    float64\n",
      " 2   Exp2      902 non-null    float64\n",
      " 3   Exp3      900 non-null    float64\n",
      " 4   Exp4      899 non-null    float64\n",
      " 5   Exp5      900 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 42.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# View the summary of the dataframe df_sub\n",
    "\n",
    "print(df_sub.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Funzioni \"isna ()\" e \"notna ()\" per rilevare i valori \"NA\"\n",
    "\n",
    "Pandas fornisce le funzioni \"isna ()\" e \"notna ()\" per rilevare i valori \"NA\". Questi sono anche metodi su oggetti Series e DataFrame.\n",
    "\n",
    "\n",
    "Esempi di comandi \"isna ()\" e \"notna ()\"\n",
    "\n",
    "\n",
    "* rileva i valori \"NA\" nel dataframe *\n",
    "\n",
    "\"df.isna ()\"\n",
    "\n",
    "\n",
    "* rileva i valori \"NA\" in una particolare colonna nel dataframe *\n",
    "\n",
    "`pd.isna (df [col_name])`\n",
    "\n",
    "`df [nome_col] .notna ()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP    23\n",
      "Exp1        13\n",
      "Exp2        11\n",
      "Exp3        13\n",
      "Exp4        14\n",
      "Exp5        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View the number of missing values in each column of dataframe df_sub\n",
    "\n",
    "print(df_sub.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "Possiamo vedere che le colonne ** YEARSEXP **, ** Exp1 **, ** Exp2 **, ** Exp3 **, ** Exp4 ** e ** Exp5 ** contengono 23, 13, 11, 13, 14 e 13 valori mancanti rispettivamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gestisci i valori mancanti\n",
    "\n",
    "Esistono diversi metodi per gestire i valori mancanti. Ogni metodo ha i suoi vantaggi e svantaggi. La scelta del metodo è soggettiva e dipende dalla natura dei dati e dai valori mancanti. Di seguito è riportato il riepilogo delle opzioni disponibili per la gestione dei valori mancanti: -\n",
    "\n",
    "** • Elimina i valori mancanti con dropna () **\n",
    "\n",
    "** • Riempi i valori mancanti con una statistica di prova **\n",
    "\n",
    "** • Riempi i valori mancanti con Imputer **\n",
    "\n",
    "** • Crea un modello di previsione **\n",
    "\n",
    "** • Imputazioni KNN **\n",
    "\n",
    "\n",
    "\n",
    "Ho discusso ogni metodo nelle sezioni seguenti: -\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Elimina i valori mancanti con dropna ()\n",
    "\n",
    "Questo è il metodo più semplice per gestire i valori mancanti. In questo metodo, rilasciamo etichette o colonne da un set di dati che si riferiscono a valori mancanti.\n",
    "\n",
    "\n",
    "rilascia etichette o righe da un set di dati contenente valori mancanti\n",
    "\n",
    "\"df.dropna (asse = 0)\"\n",
    "\n",
    "\n",
    "\n",
    "eliminare colonne da un set di dati contenente valori mancanti\n",
    "\n",
    "\"df.dropna (asse = 1)\"\n",
    "\n",
    "\n",
    "Questo è il metodo Pandas dataframe ** dropna () **. Un metodo ** dropna () ** equivalente è disponibile per le serie con la stessa funzionalità.\n",
    "\n",
    "\n",
    "\n",
    "Per eliminare una colonna specifica dal dataframe, possiamo utilizzare il metodo drop () di Pandas dataframe.\n",
    "\n",
    "\n",
    "\n",
    "### elimina la colonna col_name dal dataframe di Pandas\n",
    "\n",
    "\n",
    "`df.drop(‘col_name’, axis = 1)` \n",
    "\n",
    "\n",
    "** Una nota sul parametro dell'asse **\n",
    "\n",
    "\n",
    "Il valore dell'asse può contenere (0 o \"indice\") o (1 o \"colonne\"). Il suo valore predefinito è 0.\n",
    "\n",
    "Impostiamo axis = 0 o \"index\" per eliminare le righe che contengono valori mancanti.\n",
    "\n",
    "Impostiamo asse = 1 o \"colonne\" per eliminare le colonne che contengono valori mancanti.\n",
    "\n",
    "\n",
    "\n",
    "Dopo aver eliminato i valori mancanti, possiamo nuovamente verificare la presenza di valori mancanti e le dimensioni del dataframe.\n",
    "\n",
    "\n",
    "\n",
    "controlla di nuovo i valori mancanti in ogni colonna\n",
    "\n",
    "\"df.isnull.sum ()\"\n",
    "\n",
    "\n",
    "controlla di nuovo le dimensioni del set di dati\n",
    "\n",
    "\"df.shape\"\n",
    "\n",
    "\n",
    "\n",
    "Ma questo metodo ha uno svantaggio. Comporta il rischio di perdere informazioni utili. Supponiamo che ci siano molti valori mancanti nel nostro set di dati. Se li rilasciamo, potremmo finire per gettare via preziose informazioni insieme ai dati mancanti. È un errore molto grave in quanto comporta la perdita di informazioni chiave. Quindi, è consigliato solo quando ci sono solo pochi valori mancanti nel nostro set di dati.\n",
    "\n",
    "\n",
    "Quindi, è meglio sviluppare una strategia di imputazione in modo da poter attribuire i valori mancanti con la media o la mediana della riga o della colonna contenente i valori mancanti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe df_sub\n",
    "\n",
    "df1 = df_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP    23\n",
      "Exp1        13\n",
      "Exp2        11\n",
      "Exp3        13\n",
      "Exp4        14\n",
      "Exp5        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View the number of missing values in each column of dataframe df1\n",
    "\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "La colonna ** Exp2 ** contiene il numero minimo di valori mancanti. Quindi, lascerò cadere quella colonna da df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column Exp2 from df1\n",
    "\n",
    "df1 = df1.drop('Exp2', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEARSEXP  Exp1  Exp3  Exp4  Exp5\n",
      "0      14.0   4.0   4.0   1.0   2.0\n",
      "1      18.0   2.0   4.0   2.0   4.0\n",
      "2      13.0   2.0   2.0   1.0   3.0\n",
      "3      13.0   4.0   3.0   3.0   4.0\n",
      "4       8.0   5.0   5.0   4.0   4.0\n"
     ]
    }
   ],
   "source": [
    "# View the first five rows of dataframe df1\n",
    "\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913 entries, 0 to 912\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   YEARSEXP  890 non-null    float64\n",
      " 1   Exp1      900 non-null    float64\n",
      " 2   Exp3      900 non-null    float64\n",
      " 3   Exp4      899 non-null    float64\n",
      " 4   Exp5      900 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 35.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# View the summary of dataframe df1\n",
    "\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Conclusione**\n",
    "\n",
    "Ho eliminato la colonna ** Exp2 ** dal dataframe df1 con il comando df1.drop ()."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Riempi i valori mancanti con una statistica di prova\n",
    "\n",
    "In questo metodo, riempiamo i valori mancanti con una statistica di test come media, mediana o modalità della caratteristica particolare a cui appartiene il valore mancante. È anche possibile specificare un riempimento in avanti o un riempimento a ritroso per propagare i valori successivi all'indietro o il valore precedente in avanti.\n",
    "\n",
    "\n",
    "Riempire i valori mancanti con una statistica di test come la mediana\n",
    "\n",
    "`median = df ['col_name']. median ()`\n",
    "\n",
    "`df ['col_name']. fillna (value = median, inplace = True)`\n",
    "\n",
    "\n",
    "\n",
    "Possiamo anche usare replace () al posto di fillna ()\n",
    "\n",
    "\"df [\" col_name \"]. replace (to_replace = NaN, value = median, inplace = True)\"\n",
    "\n",
    "\n",
    "Se scegliamo questo metodo, dovremmo calcolare il valore mediano sul training set e usarlo per riempire i valori mancanti nel training set. Quindi dovremmo salvare il valore mediano che abbiamo calcolato. Successivamente, sostituiremo i valori mancanti nel set di test con il valore mediano per valutare il sistema."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the df1 dataframe\n",
    "\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP    23\n",
      "Exp1        13\n",
      "Exp3        13\n",
      "Exp4        14\n",
      "Exp5        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View the number of missing values in each column of dataframe df2\n",
    "\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Possiamo vedere che la colonna ** YEARSEXP ** contiene 23 valori mancanti. Riempirò i valori mancanti nella colonna ** YEARSEXP ** con la mediana della colonna ** YEARSEXP **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in YEARSEXP column with median of YEARSEXP column.\n",
    "\n",
    "median = df2['YEARSEXP'].median()\n",
    "\n",
    "df2['YEARSEXP'].fillna(value = median, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913 entries, 0 to 912\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   YEARSEXP  913 non-null    float64\n",
      " 1   Exp1      900 non-null    float64\n",
      " 2   Exp3      900 non-null    float64\n",
      " 3   Exp4      899 non-null    float64\n",
      " 4   Exp5      900 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 35.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# View the summary of df2 dataframe \n",
    "\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARSEXP     0\n",
      "Exp1        13\n",
      "Exp3        13\n",
      "Exp4        14\n",
      "Exp5        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Again view the number of missing values in each column of dataframe df2\n",
    "\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Ho riempito tutti i valori mancanti della colonna ** YEARSEXP ** con il valore mediano della colonna ** YEARSEXP **. Ora, questa colonna non ha valori mancanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Riempire i valori mancanti con Imputer\n",
    "\n",
    "Scikit-Learn fornisce la classe Imputer per gestire i valori mancanti. In questo metodo, sostituiamo il valore mancante con il valore medio dell'intera colonna delle caratteristiche. Questo può essere fatto come mostrato nel codice seguente:\n",
    "`from sklearn.preprocessing import Imputer`\n",
    "\n",
    "`imp = Imputer(missing_values='NaN',  strategy='mean', axis=0)`\n",
    "\n",
    "\n",
    "`imputed_data = imp.fit_transform(df)`\n",
    "\n",
    "`imputed_data`\n",
    "Qui, ho sostituito ogni valore \"NaN\" con il valore medio corrispondente. Il valore medio viene calcolato separatamente per ciascuna colonna delle caratteristiche. Se invece di axis = 0, impostiamo axis = 1, i valori medi vengono calcolati per ogni riga.\n",
    "\n",
    "\n",
    "Altre opzioni per il parametro della strategia sono \"median\" o \"most_frequent\". Il parametro \"most_frequent\" sostituisce i valori mancanti con il valore più frequente. È utile per imputare i valori delle caratteristiche categoriali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\ProgrammiSviluppo\\Anaconda3\\envs\\wiki4HEProject\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-53b1a1054307>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Fill missing values with Imputer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mImputer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mimp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImputer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmissing_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'NaN'\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mstrategy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'mean'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\ProgrammiSviluppo\\Anaconda3\\envs\\wiki4HEProject\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Fill missing values with Imputer\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN',  strategy='mean', axis=0)\n",
    "\n",
    "df2 = imp.fit_transform(df2)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer convert the dataframe df2 into a numpy array.\n",
    "\n",
    "# So, we need to convert it back into the dataframe df2.\n",
    "\n",
    "columnnames = ['YEARSEXP', 'Exp1', 'Exp3', 'Exp4', 'Exp5']\n",
    "\n",
    "df2 = pd.DataFrame(df2, columns = columnnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 rows of imputed dataframe df2\n",
    "\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the summary of the imputed dataframe df2\n",
    "\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agian check that there are no missing values in df2\n",
    "\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "We can see that there are no missing numerical values in the columns of dataframe df2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\tBuild a prediction model\n",
    "\n",
    "Possiamo costruire un modello di predizione per gestire i valori mancanti. In questo metodo, dividiamo il nostro set di dati in due set - set di allenamento e set di test. L'insieme di allenamento non contiene valori mancanti e l'insieme di prova contiene valori mancanti. La variabile che contiene valori mancanti può essere trattata come una variabile obiettivo. Successivamente, creiamo un modello per prevedere la variabile obiettivo e lo usiamo per popolare i valori mancanti del set di dati di prova."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\tKNN Imputation\n",
    "In questo metodo, i valori mancanti di un attributo sono imputati usando il numero dato di attributi che sono più simili all'attributo i cui valori sono mancanti. La somiglianza degli attributi è determinata utilizzando una funzione di distanza.\n",
    "\n",
    "I due metodi di cui sopra sono metodi più sofisticati per trattare i valori numerici mancanti. Quindi, non entrerò molto nei dettagli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check with ASSERT statement\n",
    "\n",
    "\n",
    "Finally, we can check for missing values programmatically. If we drop or fill missing values, we expect no missing values. We can write an assert statement to verify this. So, we can use an assert statement to programmatically check that no missing or unexpected ‘0’ value is present. This gives confidence that our code is running properly.\n",
    "Assert statement will return nothing if the value being tested is true and will throw an AssertionError if the value is false.\n",
    "\n",
    "Asserts\n",
    "\n",
    "•\tassert 1 == 1   (return Nothing if the value is True)\n",
    "\n",
    "•\tassert 1 == 2   (return AssertionError if the value is False)\n",
    "\n",
    "\n",
    "\n",
    "assert that there are no missing values in the dataframe\n",
    "\n",
    "`assert pd.notnull(df).all().all()`\n",
    "\n",
    "\n",
    "assert that there are no missing values for a particular column in dataframe\n",
    "\n",
    "`assert df.column_name.notnull().all()`\n",
    "\n",
    "\n",
    "assert all values are greater than 0\n",
    "\n",
    "`assert (df >=0).all().all()`\n",
    "\n",
    "\n",
    "assert no entry in a column is equal to 0\n",
    "\n",
    "`assert (df['column_name']!=0).all().all()`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that there are no missing values in the dataframe df2\n",
    "\n",
    "assert pd.notnull(df2).all().all()\n",
    "\n",
    "\n",
    "# When I run the above command, it returns nothing. Hence the assert statement is true. \n",
    "\n",
    "# So, there are no missing values in dataframe df2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that there are no missing values for a particular column in the dataframe\n",
    "\n",
    "assert df2['YEARSEXP'].notnull().all()\n",
    "\n",
    "assert df2['Exp1'].notnull().all()\n",
    "\n",
    "assert df2['Exp3'].notnull().all()\n",
    "\n",
    "assert df2['Exp4'].notnull().all()\n",
    "\n",
    "assert df2['Exp5'].notnull().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "When I run the above commands, it returns nothing. Hence the assert statements are true. Hence, there are no missing values in df2 dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our discussion on missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}